{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23348d4",
   "metadata": {},
   "source": [
    "# Cleaning code for Building 59 dataset\n",
    "\n",
    "The .csv files from the dataset are located on the path declared right below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a650843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from fancyimpute import KNN, MatrixFactorization\n",
    "import math\n",
    "\n",
    "path = \"../data\" #Path with raw csv files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca3c33",
   "metadata": {},
   "source": [
    "This is the code presented on the paper, we are not able to execute it due to RAM problems, so we will try to transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b724d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_data_from_path(path):\n",
    "    files = os.listdir(path)\n",
    "    path_postprocess = path + \"_postprocess\"\n",
    "\n",
    "    #read data files and adjust time format\n",
    "    for filename in files:\n",
    "        print(path+'/'+filename)\n",
    "        df = pd.read_csv(path+'/'+filename)\n",
    "        df['date'] = pd.to_datetime(df['date']) \n",
    "        helper=pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max(), freq='15min')})\n",
    "        df = pd.merge(df, helper, on='date', how='outer').sort_values('date')\n",
    "        count_out = Series([0],index=['date']) #count of outlier values\n",
    "        count_gap = Series([0],index=['date']) #count of gap\n",
    "        count_outgap = Series([0],index=['date']) #count of large gap (e.g., one day)\n",
    "        gap_max=Series([0],index=['date']) #maximum gap\n",
    "        #calculate the count of gap and do the interpolation based on the gap size \n",
    "        for i in range(1, len(df.columns)):\n",
    "            k = 0\n",
    "            out_gapcount=0\n",
    "            start_index = {}\n",
    "            starttime = {}\n",
    "            end_index = {}\n",
    "            endtime = {}\n",
    "            gap = {}\n",
    "            \n",
    "    \n",
    "            if pd.isnull(df.iloc[len(df.index)-1,i]) == True or math.isnan(df.iloc[len(df.index)-1,i])==True:\n",
    "                df.iloc[len(df.index)-1,i]=0\n",
    "            for j in range(0, len(df.index)):\n",
    "                if (pd.isnull(df.iloc[j,i]) or math.isnan(df.iloc[j,i]))and pd.isnull(df.iloc[j-1,i]) == False:\n",
    "                    starttime[k]=df.iloc[j-1,0] #start time of the gap\n",
    "                    start_index[k]=j-1\n",
    "                elif (pd.isnull(df.iloc[j-1,i]) or math.isnan(df.iloc[j-1,i])) and pd.isnull(df.iloc[j,i]) == False:\n",
    "                    endtime[k]=df.iloc[j,0] #end time of the gap\n",
    "                    end_index[k]=j\n",
    "                    k=k+1\n",
    "            if k != 0:\n",
    "                for m in range(k):\n",
    "                    starttime_struct=datetime.datetime.strptime(str(starttime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                    endtime_struct = datetime.datetime.strptime(str(endtime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                    gap[m]=(endtime_struct-starttime_struct).total_seconds()\n",
    "                    if  gap[m]<= 3600: #linear interpolation if the gap is less than one hour\n",
    "                        df.iloc[start_index[m]:end_index[m]+1,i]=df.iloc[start_index[m]:end_index[m]+1,i].interpolate(method='linear')\n",
    "                    elif gap[m] >3600*24:\n",
    "                        out_gapcount=out_gapcount+1\n",
    "                maxgap = max(gap.values())/60\n",
    "                gap_max=gap_max.append(Series(maxgap,index=[df.columns[i]]))\n",
    "            outcount=np.sum(df.iloc[:, i]<0)/len(df)\n",
    "            count_out=count_out.append(Series(outcount, index=[df.columns[i]]))\n",
    "            count_gap= count_gap.append(Series(k, index=[df.columns[i]]))\n",
    "            count_outgap = count_outgap.append(Series(out_gapcount,index=[df.columns[i]]))\n",
    "            df_interpolation=np.array(df.iloc[:,1:])\n",
    "        df_interpolation= KNN(k=3).fit_transform(df_interpolation) #Apply knn algorithm if the gap is larger than one hour\n",
    "        unfill_large_gaps(df_filled, df)\n",
    "        if out_gapcount !=0:\n",
    "            df_interpolation= MatrixFactorization().fit_transform(df_interpolation) #Apply MF algorithm if the gap is larger than one day         \n",
    "        df.iloc[:,1:]=df_interpolation\n",
    "        cols_not_null = (len(df)-df.count(axis=0))/len(df)\n",
    "        data=pd.DataFrame({'missingrate':cols_not_null,'outrate':count_out,'count_outgap':count_outgap,'count_gap':count_gap,'maxgap':gap_max})\n",
    "        data.to_csv(path_postprocess+'\\\\'+'parameter_'+filename, sep=',', header=True, index=True)\n",
    "        df.to_csv(path_postprocess+'\\\\'+'data_'+filename, sep=',', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb23f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b6cbd0",
   "metadata": {},
   "source": [
    "We have a problem with ele.csv (energy use), because it doesn't follow the same csv format as the other files: it includes an unnamed column without data. We solve this problem with the following code (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c038c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos = pd.read_csv(path+ '/ele.csv')\n",
    "#datos.drop('Unnamed: 6', axis=1, inplace=True)\n",
    "#datos = datos.set_index('date')\n",
    "#datos.to_csv(path+ '/ele.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed67d0",
   "metadata": {},
   "source": [
    "### Study of null values by column\n",
    "For a file, we will study the percentage of missing values it includes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27fbc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(path, filename):\n",
    "    print(\"SUMMARY OF \" + filename)\n",
    "    dataframe = pd.read_csv(path+'/'+filename)\n",
    "    dataframe=dataframe.set_index('date')\n",
    "    for i in range(dataframe.shape[1]):\n",
    "        print(dataframe.columns[i])\n",
    "        n_miss = dataframe.iloc[:,i].isnull().sum()\n",
    "        perc = n_miss / dataframe.shape[0] * 100\n",
    "        print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
    "\n",
    "def summary2(dataframe):\n",
    "    for i in range(dataframe.shape[1]):\n",
    "        print(dataframe.columns[i])\n",
    "        n_miss = dataframe.iloc[:,i].isnull().sum()\n",
    "        perc = n_miss / dataframe.shape[0] * 100\n",
    "        print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd0e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY OF ele.csv\n",
      "mels_S\n",
      "> 0, Missing: 38 (0.0%)\n",
      "lig_S\n",
      "> 1, Missing: 34 (0.0%)\n",
      "mels_N\n",
      "> 2, Missing: 24 (0.0%)\n",
      "hvac_N\n",
      "> 3, Missing: 1542 (1.5%)\n",
      "hvac_S\n",
      "> 4, Missing: 1542 (1.5%)\n"
     ]
    }
   ],
   "source": [
    "summary(path, 'ele.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac6d86",
   "metadata": {},
   "source": [
    "## Interpolation depending on the size of the gap:\n",
    "\n",
    "- If it's smaller than 1h, we use linear interpolation\n",
    "- If it's bigger than 1 day, we use KNN with n=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6c7ce",
   "metadata": {},
   "source": [
    "Interpolation with KNN: \n",
    "\n",
    "https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa9229fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "files = os.listdir(path)\n",
    "path_postprocess = path + \"_postprocess\"\n",
    "#in the cleaning code we insert the rows that are apparently missing\n",
    "\n",
    "freqs = {'zone_co2.csv':'1min', 'ele.csv': '15min', 'zone_temp_sp_c.csv':'5min', 'occ.csv':'1min', 'zone_temp_exterior.csv':'1min', 'zone_temp_sp_h.csv':'5min', 'site_weather.csv':'15min', 'wifi.csv': '10min', 'zone_temp_interior.csv':'10min'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37749eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfill_large_gaps(df_filled, df):\n",
    "    \n",
    "    for i in range(1, len(df.columns)):\n",
    "        k=0\n",
    "        start_index = {}\n",
    "        starttime = {}\n",
    "        end_index = {}\n",
    "        endtime = {}\n",
    "        gap={}\n",
    "        for j in range(0, len(df.index)):\n",
    "            if pd.isnull(df.iloc[j,i]) and pd.isnull(df.iloc[j-1,i]) == False:\n",
    "                starttime[k]=df.iloc[j-1,0]\n",
    "                start_index[k]=j-1\n",
    "            elif pd.isnull(df.iloc[j-1,i]) and pd.isnull(df.iloc[j,i]) == False:\n",
    "                endtime[k]=df.iloc[j,0]\n",
    "                end_index[k]=j\n",
    "                k=k+1\n",
    "        for m in range(k):\n",
    "            starttime_struct=datetime.datetime.strptime(str(starttime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "            endtime_struct = datetime.datetime.strptime(str(endtime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "            gap[m]=(endtime_struct-starttime_struct).total_seconds()\n",
    "            if  gap[m]>= 3600*24:\n",
    "                df_filled.iloc[start_index[m]:end_index[m]+1,i-1]= None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdc6da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_csv(path, filename, freq):\n",
    "    print(path+'/'+filename)\n",
    "    path_postprocess = path+\"_postprocess\"+'/'+filename[:-4]+ \"_postprocess.csv\"\n",
    "    df = pd.read_csv(path+'/'+filename)\n",
    "    df['date'] = pd.to_datetime(df['date']) \n",
    "    helper=pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max(), freq=freq)})\n",
    "    df = pd.merge(df, helper, on='date', how='outer').sort_values('date')\n",
    "    count_out = Series([0],index=['date']) #count of outlier values\n",
    "    count_gap = Series([0],index=['date']) #count of gap\n",
    "    count_outgap = Series([0],index=['date']) #count of large gap (e.g., one day)\n",
    "    gap_max=Series([0],index=['date']) #maximum gap\n",
    "    out_gapcount=0\n",
    "    summary2(df)\n",
    "    #calculate the count of gap and do the interpolation based on the gap size \n",
    "    for i in range(1, len(df.columns)):\n",
    "        print(\"Estamos en: \", i)\n",
    "        k = 0\n",
    "        \n",
    "        start_index = {}\n",
    "        starttime = {}\n",
    "        end_index = {}\n",
    "        endtime = {}\n",
    "        gap = {}\n",
    "        if pd.isnull(df.iloc[len(df.index)-1,i]) == True or math.isnan(df.iloc[len(df.index)-1,i])==True:\n",
    "            df.iloc[len(df.index)-1,i]=0\n",
    "        for j in range(0, len(df.index)):\n",
    "            if (pd.isnull(df.iloc[j,i]) or math.isnan(df.iloc[j,i]))and pd.isnull(df.iloc[j-1,i]) == False:\n",
    "                starttime[k]=df.iloc[j-1,0] #start time of the gap\n",
    "                start_index[k]=j-1\n",
    "            elif (pd.isnull(df.iloc[j-1,i]) or math.isnan(df.iloc[j-1,i])) and pd.isnull(df.iloc[j,i]) == False:\n",
    "                endtime[k]=df.iloc[j,0] #end time of the gap\n",
    "                end_index[k]=j\n",
    "                k=k+1\n",
    "        if k != 0:\n",
    "            for m in range(k):\n",
    "                starttime_struct=datetime.datetime.strptime(str(starttime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                endtime_struct = datetime.datetime.strptime(str(endtime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                gap[m]=(endtime_struct-starttime_struct).total_seconds()\n",
    "                if  gap[m]<= 3600: #linear interpolation if the gap is less than one hour\n",
    "                    print(\"Interpolation linear\")\n",
    "                    df.iloc[start_index[m]:end_index[m]+1,i]=df.iloc[start_index[m]:end_index[m]+1,i].interpolate(method='linear')\n",
    "                elif gap[m] >3600*24:\n",
    "                    out_gapcount=out_gapcount+1\n",
    "            maxgap = max(gap.values())/60\n",
    "            gap_max=gap_max.append(Series(maxgap,index=[df.columns[i]]))\n",
    "        outcount=np.sum(df.iloc[:, i]<0)/len(df)\n",
    "        count_out=count_out.append(Series(outcount, index=[df.columns[i]]))\n",
    "        count_gap= count_gap.append(Series(k, index=[df.columns[i]]))\n",
    "        count_outgap = count_outgap.append(Series(out_gapcount,index=[df.columns[i]]))\n",
    "    #Interpolate whole dataframe with KNN\n",
    "    df_interpolated = df.iloc[:,1:]\n",
    "    imputer = KNNImputer(n_neighbors=3, weights='distance', metric='nan_euclidean')\n",
    "    imputer.fit(df_interpolated)\n",
    "    df_interpolated = pd.DataFrame(imputer.transform(df_interpolated), columns=df_interpolated.columns)\n",
    "\n",
    "    \n",
    "    #Export into csv\n",
    "    print(\"New summary(final): \")\n",
    "    summary2(df_interpolated)\n",
    "    df.iloc[:,1:] = df_interpolated\n",
    "    df.to_csv(path_postprocess, sep=',', header=True, index=False)\n",
    "\n",
    "    #Final set of information\n",
    "    cols_not_null = (len(df)-df.count(axis=0))/len(df)\n",
    "    data=pd.DataFrame({'missingrate':cols_not_null,'outrate':count_out,'count_outgap':count_outgap,'count_gap':count_gap,'maxgap':gap_max})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9463133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/zone_co2.csv\n",
      "../data/zone_co2.csv\n",
      "date\n",
      "> 0, Missing: 0 (0.0%)\n",
      "zone_022_co2\n",
      "> 1, Missing: 167630 (22.9%)\n",
      "zone_028_co2\n",
      "> 2, Missing: 167630 (22.9%)\n",
      "zone_033_co2\n",
      "> 3, Missing: 167630 (22.9%)\n",
      "zone_040_co2\n",
      "> 4, Missing: 167630 (22.9%)\n",
      "zone_044_co2\n",
      "> 5, Missing: 167630 (22.9%)\n",
      "zone_045_co2\n",
      "> 6, Missing: 167630 (22.9%)\n",
      "zone_052_co2\n",
      "> 7, Missing: 167630 (22.9%)\n",
      "zone_058_co2\n",
      "> 8, Missing: 167630 (22.9%)\n",
      "zone_062_co2\n",
      "> 9, Missing: 167630 (22.9%)\n",
      "zone_068_co2\n",
      "> 10, Missing: 167630 (22.9%)\n",
      "zone_072_co2\n",
      "> 11, Missing: 167630 (22.9%)\n",
      "Estamos en:  1\n",
      "Estamos en:  2\n",
      "Estamos en:  3\n",
      "Estamos en:  4\n",
      "Estamos en:  5\n",
      "Estamos en:  6\n",
      "Estamos en:  7\n",
      "Estamos en:  8\n",
      "Estamos en:  9\n",
      "Estamos en:  10\n",
      "Estamos en:  11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bj/wg2_mprn1fl8bf0h7tq_sh2c0000gn/T/ipykernel_1633/923739980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mget_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/bj/wg2_mprn1fl8bf0h7tq_sh2c0000gn/T/ipykernel_1633/698573161.py\u001b[0m in \u001b[0;36mget_csv\u001b[0;34m(path, filename, freq)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nan_euclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_interpolated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mdf_interpolated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_interpolated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_interpolated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             reduce_func=process_chunk)\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mprocess_chunk\u001b[0;34m(dist_chunk, start)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# distances for samples that needed imputation for column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 dist_subset = (dist_chunk[dist_idx_map[receivers_idx] - start]\n\u001b[0m\u001b[1;32m    260\u001b[0m                                [:, potential_donors_idx])\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = os.listdir(path)\n",
    "path_postprocess = path + \"_postprocess\"\n",
    "\n",
    "#read data files and adjust time format\n",
    "for k,v in freqs.items():\n",
    "    print(path+'/'+k)\n",
    "    get_csv(path, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d3defa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mels_S</th>\n",
       "      <th>lig_S</th>\n",
       "      <th>mels_N</th>\n",
       "      <th>hvac_N</th>\n",
       "      <th>hvac_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:15:00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>19.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 01:30:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>19.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 01:45:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37.200001</td>\n",
       "      <td>18.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>24.700001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  mels_S  lig_S  mels_N     hvac_N     hvac_S\n",
       "0 2018-01-01 01:00:00     1.2    0.2     7.5  37.400002  19.500000\n",
       "1 2018-01-01 01:15:00     1.3    0.2     6.8  37.500000  19.889999\n",
       "2 2018-01-01 01:30:00     1.1    0.2     7.4  38.000000  19.299999\n",
       "3 2018-01-01 01:45:00     1.2    0.2     7.7  37.200001  18.889999\n",
       "4 2018-01-01 02:00:00     1.1    0.2     7.3  37.400002  24.700001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ele.csv')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date']) \n",
    "helper=pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max(), freq='15min')})\n",
    "prueba = pd.merge(df, helper, on='date', how='outer').sort_values('date')\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29135a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "877091ae0c5489928d44a352f429e2e80293f5d77943e3e0fbb4e56d198d5afd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
