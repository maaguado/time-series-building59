{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23348d4",
   "metadata": {},
   "source": [
    "# Cleaning code for Building 59 dataset\n",
    "\n",
    "The .csv files from the dataset are located on the path declared right below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a650843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from fancyimpute import KNN, MatrixFactorization\n",
    "import math\n",
    "\n",
    "path = \"../data\" #Path with raw csv files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca3c33",
   "metadata": {},
   "source": [
    "This is the code presented on the paper, we are not able to execute it due to RAM problems, so we will try to transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b724d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_data_from_path(path):\n",
    "    files = os.listdir(path)\n",
    "    path_postprocess = path + \"_postprocess\"\n",
    "\n",
    "    #read data files and adjust time format\n",
    "    for filename in files:\n",
    "        print(path+'/'+filename)\n",
    "        df = pd.read_csv(path+'/'+filename)\n",
    "        df['date'] = pd.to_datetime(df['date']) \n",
    "        helper=pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max(), freq='15min')})\n",
    "        df = pd.merge(df, helper, on='date', how='outer').sort_values('date')\n",
    "        count_out = Series([0],index=['date']) #count of outlier values\n",
    "        count_gap = Series([0],index=['date']) #count of gap\n",
    "        count_outgap = Series([0],index=['date']) #count of large gap (e.g., one day)\n",
    "        gap_max=Series([0],index=['date']) #maximum gap\n",
    "        #calculate the count of gap and do the interpolation based on the gap size \n",
    "        for i in range(1, len(df.columns)):\n",
    "            k = 0\n",
    "            out_gapcount=0\n",
    "            start_index = {}\n",
    "            starttime = {}\n",
    "            end_index = {}\n",
    "            endtime = {}\n",
    "            gap = {}\n",
    "            \n",
    "    \n",
    "            if pd.isnull(df.iloc[len(df.index)-1,i]) == True or math.isnan(df.iloc[len(df.index)-1,i])==True:\n",
    "                df.iloc[len(df.index)-1,i]=0\n",
    "            for j in range(0, len(df.index)):\n",
    "                if (pd.isnull(df.iloc[j,i]) or math.isnan(df.iloc[j,i]))and pd.isnull(df.iloc[j-1,i]) == False:\n",
    "                    starttime[k]=df.iloc[j-1,0] #start time of the gap\n",
    "                    start_index[k]=j-1\n",
    "                elif (pd.isnull(df.iloc[j-1,i]) or math.isnan(df.iloc[j-1,i])) and pd.isnull(df.iloc[j,i]) == False:\n",
    "                    endtime[k]=df.iloc[j,0] #end time of the gap\n",
    "                    end_index[k]=j\n",
    "                    k=k+1\n",
    "            if k != 0:\n",
    "                for m in range(k):\n",
    "                    starttime_struct=datetime.datetime.strptime(str(starttime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                    endtime_struct = datetime.datetime.strptime(str(endtime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                    gap[m]=(endtime_struct-starttime_struct).total_seconds()\n",
    "                    if  gap[m]<= 3600: #linear interpolation if the gap is less than one hour\n",
    "                        df.iloc[start_index[m]:end_index[m]+1,i]=df.iloc[start_index[m]:end_index[m]+1,i].interpolate(method='linear')\n",
    "                    elif gap[m] >3600*24:\n",
    "                        out_gapcount=out_gapcount+1\n",
    "                maxgap = max(gap.values())/60\n",
    "                gap_max=gap_max.append(Series(maxgap,index=[df.columns[i]]))\n",
    "            outcount=np.sum(df.iloc[:, i]<0)/len(df)\n",
    "            count_out=count_out.append(Series(outcount, index=[df.columns[i]]))\n",
    "            count_gap= count_gap.append(Series(k, index=[df.columns[i]]))\n",
    "            count_outgap = count_outgap.append(Series(out_gapcount,index=[df.columns[i]]))\n",
    "            df_interpolation=np.array(df.iloc[:,1:])\n",
    "        df_interpolation= KNN(k=3).fit_transform(df_interpolation) #Apply knn algorithm if the gap is larger than one hour\n",
    "        unfill_large_gaps(df_filled, df)\n",
    "        if out_gapcount !=0:\n",
    "            df_interpolation= MatrixFactorization().fit_transform(df_interpolation) #Apply MF algorithm if the gap is larger than one day         \n",
    "        df.iloc[:,1:]=df_interpolation\n",
    "        cols_not_null = (len(df)-df.count(axis=0))/len(df)\n",
    "        data=pd.DataFrame({'missingrate':cols_not_null,'outrate':count_out,'count_outgap':count_outgap,'count_gap':count_gap,'maxgap':gap_max})\n",
    "        data.to_csv(path_postprocess+'\\\\'+'parameter_'+filename, sep=',', header=True, index=True)\n",
    "        df.to_csv(path_postprocess+'\\\\'+'data_'+filename, sep=',', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb23f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b6cbd0",
   "metadata": {},
   "source": [
    "We have a problem with ele.csv (energy use), because it doesn't follow the same csv format as the other files: it includes an unnamed column without data. We solve this problem with the following code (run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c038c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos = pd.read_csv(path+ '/ele.csv')\n",
    "#datos.drop('Unnamed: 6', axis=1, inplace=True)\n",
    "#datos = datos.set_index('date')\n",
    "#datos.to_csv(path+ '/ele.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed67d0",
   "metadata": {},
   "source": [
    "### Study of null values by column\n",
    "For a file, we will study the percentage of missing values it includes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fbc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(path, filename):\n",
    "    print(\"SUMMARY OF \" + filename)\n",
    "    dataframe = pd.read_csv(path+'/'+filename)\n",
    "    dataframe=dataframe.set_index('date')\n",
    "    for i in range(dataframe.shape[1]):\n",
    "        print(dataframe.columns[i])\n",
    "        n_miss = dataframe.iloc[:,i].isnull().sum()\n",
    "        perc = n_miss / dataframe.shape[0] * 100\n",
    "        print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
    "\n",
    "def summary2(dataframe):\n",
    "    for i in range(dataframe.shape[1]):\n",
    "        print(dataframe.columns[i])\n",
    "        n_miss = dataframe.iloc[:,i].isnull().sum()\n",
    "        perc = n_miss / dataframe.shape[0] * 100\n",
    "        print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd0e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY OF ele.csv\n",
      "mels_S\n",
      "> 0, Missing: 38 (0.0%)\n",
      "lig_S\n",
      "> 1, Missing: 34 (0.0%)\n",
      "mels_N\n",
      "> 2, Missing: 24 (0.0%)\n",
      "hvac_N\n",
      "> 3, Missing: 1542 (1.5%)\n",
      "hvac_S\n",
      "> 4, Missing: 1542 (1.5%)\n"
     ]
    }
   ],
   "source": [
    "summary(path, 'ele.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac6d86",
   "metadata": {},
   "source": [
    "## Interpolation depending on the size of the gap:\n",
    "\n",
    "- If it's smaller than 1h, we use linear interpolation\n",
    "- If it's bigger than 1 day, we use KNN with n=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6c7ce",
   "metadata": {},
   "source": [
    "Interpolation with KNN: \n",
    "\n",
    "https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9229fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "files = os.listdir(path)\n",
    "path_postprocess = path + \"_postprocess\"\n",
    "#in the cleaning code we insert the rows that are apparently missing\n",
    "\n",
    "freqs = {'zone_co2.csv':'1min', 'ele.csv': '15min', 'zone_temp_sp_c.csv':'5min', 'occ.csv':'1min', 'zone_temp_exterior.csv':'1min', 'zone_temp_sp_h.csv':'5min', 'site_weather.csv':'15min', 'wifi.csv': '10min', 'zone_temp_interior.csv':'10min'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37749eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfill_large_gaps(df_filled, df):\n",
    "    \n",
    "    for i in range(1, len(df.columns)):\n",
    "        k=0\n",
    "        start_index = {}\n",
    "        starttime = {}\n",
    "        end_index = {}\n",
    "        endtime = {}\n",
    "        gap={}\n",
    "        for j in range(0, len(df.index)):\n",
    "            if pd.isnull(df.iloc[j,i]) and pd.isnull(df.iloc[j-1,i]) == False:\n",
    "                starttime[k]=df.iloc[j-1,0]\n",
    "                start_index[k]=j-1\n",
    "            elif pd.isnull(df.iloc[j-1,i]) and pd.isnull(df.iloc[j,i]) == False:\n",
    "                endtime[k]=df.iloc[j,0]\n",
    "                end_index[k]=j\n",
    "                k=k+1\n",
    "        for m in range(k):\n",
    "            starttime_struct=datetime.datetime.strptime(str(starttime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "            endtime_struct = datetime.datetime.strptime(str(endtime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "            gap[m]=(endtime_struct-starttime_struct).total_seconds()\n",
    "            if  gap[m]>= 3600*24:\n",
    "                df_filled.iloc[start_index[m]:end_index[m]+1,i-1]= None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc6da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_csv(path, filename, freq):\n",
    "    print(path+'/'+filename)\n",
    "    path_postprocess = path+\"_postprocess\"+'/'+filename[:-4]+ \"_postprocess.csv\"\n",
    "    df = pd.read_csv(path+'/'+filename)\n",
    "    df['date'] = pd.to_datetime(df['date']) \n",
    "    helper=pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max(), freq=freq)})\n",
    "    df = pd.merge(df, helper, on='date', how='outer').sort_values('date')\n",
    "    count_out = Series([0],index=['date']) #count of outlier values\n",
    "    count_gap = Series([0],index=['date']) #count of gap\n",
    "    count_outgap = Series([0],index=['date']) #count of large gap (e.g., one day)\n",
    "    gap_max=Series([0],index=['date']) #maximum gap\n",
    "    out_gapcount=0\n",
    "    summary2(df)\n",
    "    #calculate the count of gap and do the interpolation based on the gap size \n",
    "    for i in range(1, len(df.columns)):\n",
    "        print(\"Estamos en: \", i)\n",
    "        k = 0\n",
    "        \n",
    "        start_index = {}\n",
    "        starttime = {}\n",
    "        end_index = {}\n",
    "        endtime = {}\n",
    "        gap = {}\n",
    "        if pd.isnull(df.iloc[len(df.index)-1,i]) == True or math.isnan(df.iloc[len(df.index)-1,i])==True:\n",
    "            df.iloc[len(df.index)-1,i]=0\n",
    "        for j in range(0, len(df.index)):\n",
    "            if (pd.isnull(df.iloc[j,i]) or math.isnan(df.iloc[j,i]))and pd.isnull(df.iloc[j-1,i]) == False:\n",
    "                starttime[k]=df.iloc[j-1,0] #start time of the gap\n",
    "                start_index[k]=j-1\n",
    "            elif (pd.isnull(df.iloc[j-1,i]) or math.isnan(df.iloc[j-1,i])) and pd.isnull(df.iloc[j,i]) == False:\n",
    "                endtime[k]=df.iloc[j,0] #end time of the gap\n",
    "                end_index[k]=j\n",
    "                k=k+1\n",
    "        if k != 0:\n",
    "            for m in range(k):\n",
    "                starttime_struct=datetime.datetime.strptime(str(starttime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                endtime_struct = datetime.datetime.strptime(str(endtime[m]), '%Y-%m-%d %H:%M:%S')\n",
    "                gap[m]=(endtime_struct-starttime_struct).total_seconds()\n",
    "                if  gap[m]<= 3600: #linear interpolation if the gap is less than one hour\n",
    "                    print(\"Interpolation linear\")\n",
    "                    df.iloc[start_index[m]:end_index[m]+1,i]=df.iloc[start_index[m]:end_index[m]+1,i].interpolate(method='linear')\n",
    "                elif gap[m] >3600*24:\n",
    "                    out_gapcount=out_gapcount+1\n",
    "            maxgap = max(gap.values())/60\n",
    "            gap_max=gap_max.append(Series(maxgap,index=[df.columns[i]]))\n",
    "        outcount=np.sum(df.iloc[:, i]<0)/len(df)\n",
    "        count_out=count_out.append(Series(outcount, index=[df.columns[i]]))\n",
    "        count_gap= count_gap.append(Series(k, index=[df.columns[i]]))\n",
    "        count_outgap = count_outgap.append(Series(out_gapcount,index=[df.columns[i]]))\n",
    "    #Interpolate whole dataframe with KNN\n",
    "    df_interpolated = df.iloc[:,1:]\n",
    "    imputer = KNNImputer(n_neighbors=3, weights='distance', metric='nan_euclidean')\n",
    "    imputer.fit(df_interpolated)\n",
    "    df_interpolated = pd.DataFrame(imputer.transform(df_interpolated), columns=df_interpolated.columns)\n",
    "\n",
    "    \n",
    "    #Export into csv\n",
    "    print(\"New summary(final): \")\n",
    "    summary2(df_interpolated)\n",
    "    df.iloc[:,1:] = df_interpolated\n",
    "    df.to_csv(path_postprocess, sep=',', header=True, index=False)\n",
    "\n",
    "    #Final set of information\n",
    "    cols_not_null = (len(df)-df.count(axis=0))/len(df)\n",
    "    data=pd.DataFrame({'missingrate':cols_not_null,'outrate':count_out,'count_outgap':count_outgap,'count_gap':count_gap,'maxgap':gap_max})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9463133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/site_weather.csv\n",
      "date\n",
      "> 0, Missing: 0 (0.0%)\n",
      "air_temp_set_1\n",
      "> 1, Missing: 0 (0.0%)\n",
      "air_temp_set_2\n",
      "> 2, Missing: 0 (0.0%)\n",
      "dew_point_temperature_set_1d\n",
      "> 3, Missing: 0 (0.0%)\n",
      "relative_humidity_set_1\n",
      "> 4, Missing: 0 (0.0%)\n",
      "solar_radiation_set_1\n",
      "> 5, Missing: 0 (0.0%)\n",
      "Estamos en:  1\n",
      "Estamos en:  2\n",
      "Estamos en:  3\n",
      "Estamos en:  4\n",
      "Estamos en:  5\n",
      "New summary(final): \n",
      "air_temp_set_1\n",
      "> 0, Missing: 0 (0.0%)\n",
      "air_temp_set_2\n",
      "> 1, Missing: 0 (0.0%)\n",
      "dew_point_temperature_set_1d\n",
      "> 2, Missing: 0 (0.0%)\n",
      "relative_humidity_set_1\n",
      "> 3, Missing: 0 (0.0%)\n",
      "solar_radiation_set_1\n",
      "> 4, Missing: 0 (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missingrate</th>\n",
       "      <th>outrate</th>\n",
       "      <th>count_outgap</th>\n",
       "      <th>count_gap</th>\n",
       "      <th>maxgap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_temp_set_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_temp_set_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dew_point_temperature_set_1d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_humidity_set_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar_radiation_set_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              missingrate   outrate  count_outgap  count_gap  \\\n",
       "air_temp_set_1                        0.0  0.000000             0          0   \n",
       "air_temp_set_2                        0.0  0.000000             0          0   \n",
       "date                                  0.0  0.000000             0          0   \n",
       "dew_point_temperature_set_1d          0.0  0.100326             0          0   \n",
       "relative_humidity_set_1               0.0  0.000000             0          0   \n",
       "solar_radiation_set_1                 0.0  0.000000             0          0   \n",
       "\n",
       "                              maxgap  \n",
       "air_temp_set_1                   NaN  \n",
       "air_temp_set_2                   NaN  \n",
       "date                             0.0  \n",
       "dew_point_temperature_set_1d     NaN  \n",
       "relative_humidity_set_1          NaN  \n",
       "solar_radiation_set_1            NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(path)\n",
    "path_postprocess = path + \"_postprocess\"\n",
    "\n",
    "get_csv(path, 'site_weather.csv', '15min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40d3defa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mels_S</th>\n",
       "      <th>lig_S</th>\n",
       "      <th>mels_N</th>\n",
       "      <th>hvac_N</th>\n",
       "      <th>hvac_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:15:00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>19.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 01:30:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>19.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 01:45:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37.200001</td>\n",
       "      <td>18.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>24.700001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  mels_S  lig_S  mels_N     hvac_N     hvac_S\n",
       "0 2018-01-01 01:00:00     1.2    0.2     7.5  37.400002  19.500000\n",
       "1 2018-01-01 01:15:00     1.3    0.2     6.8  37.500000  19.889999\n",
       "2 2018-01-01 01:30:00     1.1    0.2     7.4  38.000000  19.299999\n",
       "3 2018-01-01 01:45:00     1.2    0.2     7.7  37.200001  18.889999\n",
       "4 2018-01-01 02:00:00     1.1    0.2     7.3  37.400002  24.700001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ele.csv')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date']) \n",
    "helper=pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max(), freq='15min')})\n",
    "prueba = pd.merge(df, helper, on='date', how='outer').sort_values('date')\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29135a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "877091ae0c5489928d44a352f429e2e80293f5d77943e3e0fbb4e56d198d5afd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
